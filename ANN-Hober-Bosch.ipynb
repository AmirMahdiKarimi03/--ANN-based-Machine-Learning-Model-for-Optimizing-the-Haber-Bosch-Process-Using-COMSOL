{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "nGg33eLrDuyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "F3omMN173kpd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize data"
      ],
      "metadata": {
        "id": "Cvu4JyN53uyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_filename = 'simulated_haber_bosch_data.csv'\n",
        "output_filename = 'normalized_data.csv'\n",
        "\n",
        "# The divisors for the columns\n",
        "divisor_col_1 = 1073.0\n",
        "divisor_col_2 = 300\n",
        "\n",
        "# CSV file into a pandas DataFrame\n",
        "try:\n",
        "    df = pd.read_csv(input_filename)\n",
        "    print(f\"✅ Successfully loaded '{input_filename}'.\")\n",
        "    print(\"\\n--- Original Data (First 5 Rows): ---\")\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\" Error: The file '{input_filename}' was not found.\")\n",
        "    print(\"Please make sure the file is in the same folder as this script, or provide the full path.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Division on the specified columns\n",
        "try:\n",
        "    col_1_name = df.columns[0]\n",
        "    col_2_name = df.columns[1]\n",
        "    df.iloc[:, 0] = df.iloc[:, 0] / divisor_col_1\n",
        "    df.iloc[:, 1] = df.iloc[:, 1] / divisor_col_2\n",
        "\n",
        "    print(f\"\\n Divided column '{col_1_name}' by {divisor_col_1}.\")\n",
        "    print(f\"Divided column '{col_2_name}' by {divisor_col_2}.\")\n",
        "\n",
        "except IndexError:\n",
        "    print(\"Error: The CSV file does not have at least two columns.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\n--- Normalized Data (First 5 Rows): ---\")\n",
        "print(df.head())\n",
        "df.to_csv(output_filename, index=False)\n",
        "print(f\"\\n Normalized data has been successfully saved to '{output_filename}'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "7D9OGW0s4nx-",
        "outputId": "0dc83ea9-5cad-4061-b9ca-74565e0e3c4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Error: The file 'simulated_haber_bosch_data.csv' was not found.\n",
            "Please make sure the file is in the same folder as this script, or provide the full path.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3013755688.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Division on the specified columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcol_1_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mcol_2_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdivisor_col_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go For ANN"
      ],
      "metadata": {
        "id": "GHT7mA9H5LPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_filename = 'normalized_data.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(input_filename)\n",
        "    print(\"Successfully loaded 'normalized_data.csv'.\")\n",
        "    print(\"\\n--- Data Head: ---\")\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{input_filename}' was not found.\")\n",
        "    print(\"Please make sure you have run the normalization script first.\")\n",
        "    exit()\n",
        "\n",
        "X = df[['Yield']]\n",
        "\n",
        "Y = df[['Temperature', 'Pressure', 'H2_Fraction']]\n",
        "\n",
        "print(\"\\n--- Shape of Input Data (X): ---\")\n",
        "print(X.shape)\n",
        "print(\"\\n--- Shape of Output Data (Y): ---\")\n",
        "print(Y.shape)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"\\nTraining set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=[1]),\n",
        "\n",
        "    layers.Dense(16, activation='relu'),\n",
        "\n",
        "    layers.Dense(16, activation='relu'),\n",
        "\n",
        "    layers.Dense(3, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error'\n",
        ")\n",
        "\n",
        "print(\"\\n--- Model Summary: ---\")\n",
        "model.summary()\n",
        "\n",
        "print(\"\\n--- Starting Model Training... ---\")\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "print(\"\\n--- Evaluating Model on Test Data... ---\")\n",
        "loss = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f\"Test Set Mean Squared Error: {loss:.4f}\")\n",
        "\n",
        "desired_yield = 0.25\n",
        "\n",
        "predicted_conditions = model.predict(np.array([[desired_yield]]))\n",
        "\n",
        "print(f\"\\n--- Prediction for a desired yield of {desired_yield*100}% ---\")\n",
        "print(f\"Predicted Normalized Temperature: {predicted_conditions[0][0]:.4f}\")\n",
        "print(f\"Predicted Normalized Pressure:    {predicted_conditions[0][1]:.4f}\")\n",
        "print(f\"Predicted Normalized H2 Fraction: {predicted_conditions[0][2]:.4f}\")\n",
        "print(\"\\nNOTE: These are normalized values. You would need to multiply them by your original divisors to get the real-world values.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "drEgYk-x5Kmb",
        "outputId": "9c5b099f-e6a2-43ba-eec5-2c6d58cbefe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully loaded 'normalized_data.csv'.\n",
            "\n",
            "--- Data Head: ---\n",
            "   Temperature  Pressure  H2_Fraction     Yield\n",
            "0     0.277726  0.166667     0.010000  0.006088\n",
            "1     0.277726  0.166667     0.019899  0.012637\n",
            "2     0.277726  0.166667     0.029798  0.019323\n",
            "3     0.277726  0.166667     0.039697  0.026122\n",
            "4     0.277726  0.166667     0.049596  0.033028\n",
            "\n",
            "--- Shape of Input Data (X): ---\n",
            "(278372, 1)\n",
            "\n",
            "--- Shape of Output Data (Y): ---\n",
            "(278372, 3)\n",
            "\n",
            "Training set size: 222697\n",
            "Testing set size: 55675\n",
            "\n",
            "--- Model Summary: ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m32\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m355\u001b[0m (1.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355</span> (1.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m355\u001b[0m (1.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355</span> (1.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training... ---\n",
            "Epoch 1/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0739 - val_loss: 0.0480\n",
            "Epoch 2/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0531 - val_loss: 0.0455\n",
            "Epoch 3/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0511 - val_loss: 0.0461\n",
            "Epoch 4/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0467 - val_loss: 0.0445\n",
            "Epoch 5/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0456 - val_loss: 0.0457\n",
            "Epoch 6/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0452 - val_loss: 0.0775\n",
            "Epoch 7/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.1348 - val_loss: 0.0434\n",
            "Epoch 8/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0441 - val_loss: 0.0653\n",
            "Epoch 9/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0447 - val_loss: 0.0457\n",
            "Epoch 10/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0446 - val_loss: 0.0522\n",
            "Epoch 11/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0444 - val_loss: 0.0442\n",
            "Epoch 12/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0439 - val_loss: 0.0521\n",
            "Epoch 13/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0446 - val_loss: 0.0435\n",
            "Epoch 14/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0447 - val_loss: 0.0432\n",
            "Epoch 15/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0444 - val_loss: 0.0517\n",
            "Epoch 16/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0437 - val_loss: 0.0449\n",
            "Epoch 17/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0443 - val_loss: 0.0441\n",
            "Epoch 18/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0438 - val_loss: 0.0443\n",
            "Epoch 19/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0438 - val_loss: 0.0441\n",
            "Epoch 20/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0452 - val_loss: 0.0436\n",
            "Epoch 21/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0439 - val_loss: 0.0469\n",
            "Epoch 22/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0433 - val_loss: 0.0436\n",
            "Epoch 23/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0435 - val_loss: 0.0425\n",
            "Epoch 24/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0430 - val_loss: 0.0427\n",
            "Epoch 25/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0430 - val_loss: 0.0422\n",
            "Epoch 26/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0427 - val_loss: 0.0428\n",
            "Epoch 27/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0425 - val_loss: 0.0425\n",
            "Epoch 28/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0424\n",
            "Epoch 29/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0426 - val_loss: 0.0422\n",
            "Epoch 30/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0422 - val_loss: 0.0430\n",
            "Epoch 31/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0422 - val_loss: 0.0420\n",
            "Epoch 32/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.0425 - val_loss: 0.0422\n",
            "Epoch 33/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0445\n",
            "Epoch 34/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0418\n",
            "Epoch 35/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0418\n",
            "Epoch 36/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0425 - val_loss: 0.0420\n",
            "Epoch 37/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: 0.0421 - val_loss: 0.0417\n",
            "Epoch 38/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0419\n",
            "Epoch 39/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.0422 - val_loss: 0.0426\n",
            "Epoch 40/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0419\n",
            "Epoch 41/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0422 - val_loss: 0.0423\n",
            "Epoch 42/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0421 - val_loss: 0.0422\n",
            "Epoch 43/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0421 - val_loss: 0.0424\n",
            "Epoch 44/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.0425 - val_loss: 0.0422\n",
            "Epoch 45/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0421 - val_loss: 0.0420\n",
            "Epoch 46/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0421 - val_loss: 0.0416\n",
            "Epoch 47/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0417\n",
            "Epoch 48/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0418\n",
            "Epoch 49/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0417\n",
            "Epoch 50/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0417\n",
            "Epoch 51/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0422 - val_loss: 0.0416\n",
            "Epoch 52/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0416\n",
            "Epoch 53/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0417\n",
            "Epoch 54/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0419\n",
            "Epoch 55/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0420\n",
            "Epoch 56/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0420\n",
            "Epoch 57/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0416 - val_loss: 0.0415\n",
            "Epoch 58/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0415\n",
            "Epoch 59/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0417\n",
            "Epoch 60/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0416\n",
            "Epoch 61/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0415\n",
            "Epoch 62/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0421\n",
            "Epoch 63/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0421\n",
            "Epoch 64/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0414\n",
            "Epoch 65/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0415\n",
            "Epoch 66/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0416 - val_loss: 0.0414\n",
            "Epoch 67/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0416 - val_loss: 0.0415\n",
            "Epoch 68/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0415 - val_loss: 0.0416\n",
            "Epoch 69/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0413\n",
            "Epoch 70/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0420\n",
            "Epoch 71/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0415\n",
            "Epoch 72/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - loss: 0.0414 - val_loss: 0.0423\n",
            "Epoch 73/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0424\n",
            "Epoch 74/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0418\n",
            "Epoch 75/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0421 - val_loss: 0.0417\n",
            "Epoch 76/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0417\n",
            "Epoch 77/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0418\n",
            "Epoch 78/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0420\n",
            "Epoch 79/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0419\n",
            "Epoch 80/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0416\n",
            "Epoch 81/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0415\n",
            "Epoch 82/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0418\n",
            "Epoch 83/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0419\n",
            "Epoch 84/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0420\n",
            "Epoch 85/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0421\n",
            "Epoch 86/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0419\n",
            "Epoch 87/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0416\n",
            "Epoch 88/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0415\n",
            "Epoch 89/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0421\n",
            "Epoch 90/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0415\n",
            "Epoch 91/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0416\n",
            "Epoch 92/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0419\n",
            "Epoch 93/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0413\n",
            "Epoch 94/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0414\n",
            "Epoch 95/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0416\n",
            "Epoch 96/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0416\n",
            "Epoch 97/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0416\n",
            "Epoch 98/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0414\n",
            "Epoch 99/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0414\n",
            "Epoch 100/100\n",
            "\u001b[1m5568/5568\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0416 - val_loss: 0.0414\n",
            "✅ Model training complete.\n",
            "\n",
            "--- Evaluating Model on Test Data... ---\n",
            "Test Set Mean Squared Error: 0.0415\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\n",
            "--- Prediction for a desired yield of 25.0% ---\n",
            "Predicted Normalized Temperature: 0.3654\n",
            "Predicted Normalized Pressure:    0.5559\n",
            "Predicted Normalized H2 Fraction: 0.4344\n",
            "\n",
            "NOTE: These are normalized values. You would need to multiply them by your original divisors to get the real-world values.\n"
          ]
        }
      ]
    }
  ]
}